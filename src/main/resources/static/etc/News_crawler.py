#!/usr/bin/env python
# coding: utf-8

# In[2]:


pip install selenium


# In[3]:


pip install beautifulsoup4


# In[6]:


pip install pandas


# In[8]:


pip install webdriver-manager


# In[60]:


from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import pandas as pd
import json

# í¬ë¡¬ ì˜µì…˜ ì„¤ì •
options = webdriver.ChromeOptions()
# options.add_argument('--headless')  # ì°½ ë„ìš°ê³  ë””ë²„ê¹… ê°€ëŠ¥í•˜ê²Œ
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')
options.add_argument('--window-size=1920,1080')

# ë¸Œë¼ìš°ì € ì‹¤í–‰
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
driver.get("https://www.mohw.go.kr/board.es?mid=a10503000000&bid=0027")

# DOM ë¡œë”© ëŒ€ê¸°
WebDriverWait(driver, 10).until(
    EC.presence_of_element_located((By.CSS_SELECTOR, "a.txt_title"))
)

# HTML ì €ì¥ (ë””ë²„ê¹…ìš©)
html = driver.page_source
with open("debug_output.html", "w", encoding="utf-8") as f:
    f.write(html)

driver.quit()

# íŒŒì‹±
soup = BeautifulSoup(html, "html.parser")

# âœ… ì œëª©ì—ì„œ 'ìƒˆê¸€' ë¬¸êµ¬ ì œê±°
titles = [a.text.replace("ìƒˆê¸€", "").strip() for a in soup.select("a.txt_title")]
dates = [d.text.strip() for d in soup.select('td[data-label="ë“±ë¡ì¼"]')]
links = ["https://www.mohw.go.kr" + a['href'] for a in soup.select("a.txt_title")]

print("ì œëª© ìˆ˜:", len(titles))
print("ë‚ ì§œ ìˆ˜:", len(dates))
print("ë§í¬ ìˆ˜:", len(links))

# ì €ì¥
data = {"title": titles, "date": dates, "link": links}
df = pd.DataFrame(data)

df.to_csv("mohw_news.csv", index=False, encoding="utf-8-sig")
with open("C:/Users/14A/mohw_news.json", "w", encoding="utf-8") as f:
    json.dump(data, f, indent=2, ensure_ascii=False)

print("âœ… ë¶ˆí•„ìš”í•œ ë¬¸êµ¬ ì œê±° ì™„ë£Œ + í¬ë¡¤ë§ ì„±ê³µ ğŸ¯")


# In[62]:


get_ipython().system('jupyter nbconvert --to script News_crawler.ipynb')

